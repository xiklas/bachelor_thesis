%!TEX root = ../thesis.tex
\chapter{Results}
\label{ch:03results}

This chapter serves to present the results of our experiments.
In total, 240 individual trials were conducted across various LLM configurations to find out whether the inclusion of qualitative geographic context helps improve the navigation performance of LLMs.
We are first going to provide an overview of the results obtained from our experiments, before breaking down the results by different factors such as test city or Large Language Model tested.
Subsequently, we will present the results of our statistical significance testing.
These results will then be summarized and serve as the basis for the discussion following in the Chapter 5.

% Overview of Task Success Rates

\section{Experiment Results}

\begin{table}[h!]
\centering
\begin{tabular}{l c c c c}
\hline
\textbf{Group} & \textbf{\# Experiments} & \textbf{\# Successful} & \textbf{\# Failed} & \textbf{Success Rate (\%)} \\
\hline
Control Group & 120 & 0  & 120 & 0\% \\
Test Group    & 120 & 75 & 45  & 62.5\% \\
\hline
\textbf{Total} & \textbf{240} & \textbf{75} & \textbf{165} & \textbf{31.25\%} \\
\hline
\end{tabular}
\caption{Overview of experiment results in control and test groups with success and failure counts and complimentary success rates.}
\end{table}

% Could all data be collected successfully?

All trials could be executed successfully by the methods described in Chapter 3. 
This means that we got a valid LLM response for each navigation task under all test conditions.
However, this does not imply that all responses were correct in terms of navigation success, but simply that we were able to collect all the necessary data.
In total, 240 navigation tasks were answered by the LLMs and manually labeled as either correct or incorrect.
Table 4.1 summarizes the overall results of our experiments.

% What is the total performance gain between control and test group?

There is a visible difference in navigation task success rates between the control and test groups.
In each group, the exact same 120 navigation tasks were executed.
Out of these 120 tasks, no trial in the control group could be labeled as successful.
Consequently, all trials in this group were labeled as failures, leading to a task success rate of 0\%.
In the test group however, 75 out of 120 trials could be labeled as successful.
With 45 remaining failures, this results in a task success rate of 62.5\%.
Across both groups, this means that 75 out of 240 navigation tasks were successfully answered, while 165 tasks were answered incorrectly.
This leads to an overall task success rate of 31.25\% across all experiments conducted in this thesis.
To summarize, the inclusion of qualitative geographic context in the test group led to an increase in task success rate by 62.5\% when compared to the control group.

% Comparing Test Group Performance By City

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/tg_by_city.png} % Adjust width as needed
    \caption{Test Group Performance by City.}
    \label{fig:pasted_graphic}
\end{figure}

When comparing the test group performance across the two test cities, we can make several key observations.
First, the task success rate was increased in both cities compared to the control group (which had a success rate of 0\% in both cities).
In Hamburg, the task success rate climbed to 86.6\% while in Münster it reached just 38.3\%.
This means that the task success rate in Hamburg was more than double that of Münster.
Out of the 75 correctly answered navigation tasks in the test group, 52 were from Hamburg, while only 23 were from navigation trials conducted using the Münster dataset.

% Breakdown Per Model

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/tg_rate_by_model.png} % Adjust width as needed
    \caption{Test Group Performance by LLM.}
    \label{fig:pasted_graphic}
\end{figure}

Further, comparing the test group performance across the three tested LLMs as depicted in Figure 4.2, we are able to observe that while all LLMs performed better, there are noteworthy differences in their performance increase.
While all models performed better compared to their control group performance of 0\%, the model which performed best across all trials in the test group was Google's Gemini 2.5 Pro.
It achieved a task success rate of 70\%, answering 28 out of 40 navigation tasks correctly.
The next best performing model was Claude 4.5, which achieved a slightly lower task success rate of 65\%.
Claude answered 26 out of 40 navigation tasks correctly.
In total, the worst performing model in the test group was GPT-4o, with 21 correct answers out of 40 possible, amounting to a task success rate of 52.5\%.

% Breakdown per city and model

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/model_city.png} % Adjust width as needed
    \caption{Test Group Performance by LLM per city.}
    \label{fig:pasted_graphic}
\end{figure}

Breaking down the test group performance by both test city and LLM as shown in Figure 4.3 leads to several valuable observations.
First, we can see that all models performed better with the Hamburg dataset compared to the Münster dataset.
All models using the Hamburg dataset scored at least 75\% task success rate, with Gemini 2.5 ranking the highest at 95\%.
Claude 4.5 followed with a task success rate of 90\%, a decrease of 5\%, and ChatGPT-4o achieved a task success rate of 75\%, which is 20\% lower than Gemini 2.5.
With the Münster dataset, all models performed worse overall, although their relative rankings toward each other remained the same.
Gemini 2.5 again ranked highest among the three with a task success rate of 45\%, followed by Claude 4.5 at 40\% and GPT-4o at 30\%.
The lowest overall task success rate in the test group was thus observed with GPT-4o using the Münster dataset at 30\%, while the highest overall task success rate was achieved by Gemini 2.5 using the Hamburg dataset at 95\%.

% How many tasks were correctly answered by all models?

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Number of Correct LLM Responses} & \textbf{Frequency} \\
\hline
0 & 6 \\
\hline
1 & 9 \\
\hline
2 & 9 \\
\hline
3 & 16 \\
\hline
\end{tabular}
\caption{\textbf{Frequency Distribution of Correct LLM Responses}}
\label{tab:llm_frequency}
\end{table}

We may also take a look at the frequency distribution of correctly answered navigation tasks in the test group.
The above Table 4.2 summarizes how many navigation tasks were answered correctly by how many models in this group.
Only six navigation tasks were answered incorrectly by all three models.
Counting the occurences of navigation tasks where just one model gave a correct answer, we find that there are nine such tasks.
The occurence of two correct answers per navigation task is also nine.
This means that the likelihood of all models failing when at least one model failed was exactly 25\% (The number of cases where all models failed (6) divided by the number of cases where at least one model failed (24)).
The highest frequency could be observed for navigation tasks where all three models answered correctly, with a total of 16.
Conversely, this means that the likelihood of all models answering correctly when at least one model answered correctly was approximately 47.06\% (The number of cases where all models answered correctly (16) divided by the number of cases where at least one model answered correctly (34)).

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{At Least $x$ Correct LLMs} & \textbf{Cumulative \%} & \textbf{Drop Relative to Previous Group} \\
\hline
0 & 100.0\% & N/A \\
\hline
1 & 85.0\% & 15.0\% \\
\hline
2 & 62.5\% & 22.5\% \\
\hline
3 & 40.0\% & 22.5\% \\
\hline
\end{tabular}
\caption{\textbf{Cumulative Percentage Distribution of Correct LLM Responses with Group Drop}}
\label{tab:llm_cumulative_drop}
\end{table}

Looking at these results in another way, we can analyze the cumulative percentage distribution of correctly answered navigation tasks.
To no surprise, the percentage of navigation tasks where at least zero models answered correctly is 100\%.
85\% of navigation tasks were answered correctly by at least one model.
The percentage then drops to 62.5\% for navigation tasks where at least two models answered correctly.
Lastly, just 40\% of navigation tasks were answered correctly by all three models.
This means that from zero correct responses to one correct response, there is a drop of 15\%.
From one to two and two to three correct responses, there is a drop of 22.5\% each.
In total, this results in an overall drop of 60\% from zero to three correct responses.

% Which model performed best when only one model succeeded?

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Model} & \textbf{Frequency} \\
\hline
GPT & 3 \\
\hline
Gemini & 4 \\
\hline
Claude & 2 \\
\hline
\end{tabular}
\caption{\textbf{Distribution of Correct Models in Single-Success Trials}}
\label{tab:single_correct_llm}
\end{table}

Additionally, we analyzed which model performed best when just one model succeeded in answering a navigation task correctly.
Although there are just nine such cases overall and the results deviate by just two between the best and worst performing model, the winner in this category is also Gemini 2.5.
It answered four navigation tasks correctly where both other models failed.
GPT-4o then followed with three such cases.
Claude 4.5 performed worst in this category, answering just two navigation tasks correctly when no other model could. 

% When just one model failed, which model was most likely to fail?

\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Model Failed} & \textbf{Frequency} \\
\hline
GPT & 7 \\
\hline
Gemini & 1 \\
\hline
Claude & 1 \\
\hline
\end{tabular}
\caption{\textbf{Distribution of Single Failed Model in Two-Success Trials}}
\label{tab:single_failed_llm}
\end{table}

We may also look at the inverse case: When just one model failed, which model was most likely to be the one failing?
The results of this analysis paint a clearer picture:
out of the nine occurences where just one model failed, GPT-4o was responsible for seven of these failures.
Both Gemini 2.5 and Claude 4.5 were only responsible for one failure of this kind each.

% Failures by City

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Number of Failed Models} & \textbf{Hamburg} & \textbf{Münster} \\
\hline
1 & 4 & 5 \\
\hline
2 & 2 & 7 \\
\hline
3 & 0 & 6 \\
\hline
\textbf{Total} & \textbf{6} & \textbf{18} \\
\hline
\end{tabular}
\caption{\textbf{Distribution of Failures by City and Number of Failed Models}}
\label{tab:failures_by_city}
\end{table}

Lastly, we may analyze the failures in the test group by the dataset they occured on.
While failures where just one model failed to answer a navigation task occured almost equally in both cities, the results look different for failures by two or even three models.
In Hamburg, there were 4 occurences where one model failed to answer a navigation task.
In Münster, this number was just slightly higher at 5.
In the next category however, where two models failed to answer a navigation task, there were two such occurences in Hamburg and seven in Münster.
The last category presents the most striking difference:
No navigation trial in Hamburg resulted in all three models failing to provide a correct answer.
In Münster however, there were six such occurences.
Counting together the occurences of failures, we find that six out of a total 24 failure cases occured in Hamburg, while 18 occured in Münster.
As a percentage, this means that 25\% and 75\% of failures occured in Hamburg and Münster respectively.
Shifting our view at failure cases where at least two models failed, just two out of a total of 15, or 13.33\% of such cases occured in Hamburg, while 13 out of 15, or 86.67\% occured in Münster.
Counting just the cases where all three models failed, 100\% of the failures can be attributed to navigation tasks in Münster.

% Statistical Significance Testing

\section{Statistical Significance Testing}

In this section we present the results of our statistical significance testing using the Chi-Squared test for independence.
To start, we constructed a contingency table based on the overall success and failure counts from our experiments:

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Outcome} & \textbf{Control Group} & \textbf{Test Group} & \textbf{Row Total} \\
        \hline
        \textbf{Success} & 0 & 75 & 75 \\
        \textbf{Failure} & 120 & 45 & 165 \\
        \hline
        \textbf{Column Total} & 120 & 120 & 240 \\
        \hline
    \end{tabular}
    \caption{Final contingency table of experiment outcomes.}
    \label{tab:final_contingency}
\end{table}

The above table 4.6 summarizes our experiment outcomes.
In the control group, there were 0 successful navigation attempts and 120 failed attempts.
The test group answered 75 navigation tasks successfully, while failing at 45 tasks.
In total, 75 navigation tasks were answered successfully across both groups, while 165 tasks were answered incorrectly.

Calculating the expected frequencies for each cell in the contingency table yields the following results:

\begin{table}[h]
    \centering
    \label{tab:chi_squared_calc}
    \begin{tabular}{|l|c|c|c|c|c|c|}
        \hline
        \textbf{Cell} & \textbf{Observed ($O$)} & \textbf{Expected ($E$)} & $\mathbf{(O - E)}$ & $\mathbf{(O - E)^2}$ & $\mathbf{(O - E)^2/E}$ & \textbf{Contribution} \\
        \hline
        Success, Control (S, C) & 0 & 37.5 & $-37.5$ & 1406.25 & $\frac{1406.25}{37.5}$ & 37.500 \\
        \hline
        Success, Test (S, T) & 75 & 37.5 & $37.5$ & 1406.25 & $\frac{1406.25}{37.5}$ & 37.500 \\
        \hline
        Failure, Control (F, C) & 120 & 82.5 & $37.5$ & 1406.25 & $\frac{1406.25}{82.5}$ & 17.045 \\
        \hline
        Failure, Test (F, T) & 45 & 82.5 & $-37.5$ & 1406.25 & $\frac{1406.25}{82.5}$ & 17.045 \\
        \hline
        \multicolumn{6}{|r|}{\textbf{Total Chi-Squared ($\chi^2$)}} & \textbf{109.091} \\
        \hline
    \end{tabular}
    \caption{Results for the Chi-Squared ($\chi^2$) test for independence.}
\end{table}

Each cell's contribution to the overall Chi-Squared statistic is calculated in the same manner:
The difference between observed and expected frequencies is squared and then divided by the expected frequencies.
Summing up the contributions from all four cells finally yields the total Chi-Squared statistic.
In our case, this results in a Chi-Squared statistic of 109.091.
The largest contributions to this value stem from the success cells for the Control and Test groups, with both of them contributing 37.500 each.
The failure cells contributed less, with 17.045 each.

For our 2x2 contingency table, we have 1 degree of freedom.
The degree of freedom can be calculated by multiplying the number of rows minus one by the number of columns minus one.
In our case the calculation is thus simply: (2-1) * (2-1) = 1.



\section{Summary of Findings}

In summary, our experiments revealed that LLM navigation perfomance with additional geographic context was higher than without it.
This effect was not limited to a specific city or model, but could be observed across all combinations tested in this study.



