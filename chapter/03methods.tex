%!TEX root = ../thesis.tex
\chapter{Methods}
\label{ch:03methods}

% Chapter Introduction:
% Outlines the scope and structure of the Methods chapter.

In this chapter, we introduce the methods used in this thesis.
Our research hypothesis states that the navigation capabilities of large language models may be substantially improved by the inclusion of qualitative geographic context.
To test our hypothesis, we designed an experimental setup involving large language models, qualitative geographic context and navigation tasks.
Our approach can be broken down into the data used, the configuration of the LLMs - including the context enrichment setup -, and ultimately the procedures used to conduct the experiments.
To evaluate the results, we define a strict correctness criterion and compute task success rates for the control and test groups.


% Data Acquisition and Preparation:
% Describes how the data used in the experiments was collected and prepared.

\section{Data Acquisition and Preparation}

% Why the data is not readily available on the internet.

The first step in our experimental setup is the generation of dipole relations describing topological relationships in street networks which can then be used as qualitative geographic context for our LLMs.
While high quality geographic datasets on street networks are available at no additional cost from various sources such as OpenStreetMap, these datasets typically do not include qualitative geographic descriptions.
The most common way of encountering street network data is in the form of graphml files which describe the street network as a graph of nodes and edges:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{chapter/hamburg.png} % Reduced to 60% of text width
    \caption{Graph representation of area of interest in Hamburg, Germany as used in this study.}
    \label{fig:graphic6}
\end{figure}

% Which data was downloaded and how was it processed to generate the dipole relations.

As a basis for our experiments, we downloaded two of these graphs from the OpenStreetMap database using OSMnx, a powerful Python library capable of handling and processing OpenStreetMap data.
In order to ensure a reasonable degree of geographic variation, we selected two different cities as sites for our datasets: Hamburg and Münster.
This way, we end up with one dataset per city, each containing a varying number of nodes and edges.
To extract qualitative descriptions from these datasets, an algorithm capable of generating dipole relations in natural language describing the topology of a given graph was used.
In essence, the algorithm works by iterating over all nodes and creating dipole relations for each intersection.
While the full algorithm is provided in the appendix, a conceptual description of the algorithm in pseudocode is given here:

\begin{algorithm}
\caption{Generate Street Descriptions from OSM}
\label{alg:street_desc}
\begin{algorithmic}[1]
\Require Bounding box
\Ensure Text descriptions for streets in bounding box
\State Download road network for bounding box
\State Remove motorways and isolated nodes
\For{each street name in network}
    \State Collect all road segments with this name
    \State Keep largest connected component
    \State Find main end-to-end path
    \State Orient path consistently (S$\to$N or W$\to$E)
    \For{each junction along path}
        \State Inspect connected streets
        \State Use bearings to classify as left/right/crossing
        \State Generate natural-language statement
    \EndFor
\EndFor
\State Export all descriptions to file
\end{algorithmic}
\end{algorithm}

% How was the data stored and how can the data be described.

Following this method, we were able to generate a set of dipole relations for each of our initial street network datasets.
These relations were stored in the form of simple .txt files, with one relation per line.
An example of these relations is given in the appendix. 
To demonstrate the relations here, a small excerpt may be helpful:

\begin{tcolorbox}[title={Excerpt of qualitative relations (Hamburg)}, colback=white]
\small
\begin{verbatim}
Borchlingweg begins at the intersection with Ansorgestraße, Halbmondsweg.
Stindeweg then branches off to the right.
Langmaackweg then branches off to the right.
\end{verbatim}
\end{tcolorbox}

The python software used to generate the qualitative dipole relations was primarily implemented  by James Odienki, and the code is available upon request.
After discussing the data acquisition process, we now focus on a detailed description of the configuration of the LLMs used in this study.

% Which LLMs were selected and how were they configured.

\section{LLM Configuration}

% Why using the proprietary web interfaces is impractical for this study.

While the most common way for users to interact with large language models is to use their proprietary web interfaces, we identified this approach to be impractical for our needs;
namely to test multiple configurations of LLMs in a systematic manner.
While most LLM providers also offer APIs to interact with their models, this approach would have introduced additional programming overhead for this project.

% Why openrouter was selected and how the platform works.

One additional solution to access a wide range of current or legacy LLMs through a unified interface is to use a platform like OpenRouter, which is the platform we have chosen to use for this study.
Through its user-friendly web interface it is possible to query multiple LLMs concurrently without any additional programming effort.
It is important to note however, that even though OpenRouter makes it possible to query multiple LLMs at the same time, this does not mean that the queried models share a common context window or share any other information between each other.

% Which models were selected and why.

New models arrive on the market frequently, making it difficult to test "the latest" or "state of the art" models.
After all, a model with significantly greater capabilities in various areas could be just around the corner at any given time.
Nevertheless, we have selected three models which we consider to be widely used and capable of handling navigation tasks due to their advertised abilities of performing multi-step reasoning tasks.
Our selection of models for this study therefore consists of OpenAI's GPT-4o, Google's Gemini 2.5 Pro as well as Anthropic's Claude Sonnet 4.5.

% How was the qualitative context provided to the models?

The symbolic dipole relations generated by the process described in the previous section were stored in a simple .txt file.
For the navigation tasks, this file was provided to the models using OpenRouter's file upload (attachment) feature, allowing the models to reference the contained relations while generating a route.
To ensure the model responses were free of any web-search result contamination, we switched off any web-search tools available and used a simple system prompt telling the models to use their own inherent knowledge to solve the given tasks only.
The exact system prompts used in our experiments are provided in the appendix.
In the trials conducted with additional qualitative geographic context, the system prompt was extended to instruct the models to use the provided dipole relations when figuring out a route.
Other than that, no further changes were made to the model's default configurations, making the setup easy to replicate and true to real-world usage scenarios.

% How was the experimental procedure designed?

\section{Experimental Design and Procedure}

% Traditional A/B testing approach with Test and Control Group.

Our experimental design follows a traditional A/B testing approach, where we compare the performance of a Control Group against the performance of a Test Group.
In our case, the Control Group consists of LLMs performing navigation tasks on their own, without any additional context.
Respectively, the Test Group consists of LLMs performing the same navigation tasks, but with access to our dipole relations.
While the Test Group performs the exact same tasks as the Control Group, it was ensured that no memories of previous trials were available to the models in the Test Group sessions by starting each individual trial of both groups in a fresh session, disconnected from any previously conducted trials.

% How were the navigation tasks designed and executed?

To reduce the risk of bias towards certain areas or street types, we designed navigation tasks which consist of two street names (start street and end street), both derived randomly from the available street names.
The first step was to extract a list of unique street names from both datasets (Hamburg and Münster).
These lists were then sampled uniformly at random 20 times with replacement each to generate start streets for the navigation tasks.
To make sure that we receive 20 unique start streets per dataset, any duplicates were removed and replaced by new random samples.
This process was repeated to generate the end streets for the navigation tasks.
In case any start and end street pairs were identical, these pairs were also replaced by new random samples.
In a final check, we ensured that all generated navigation tasks were unique within each dataset.
In total, this results in 40 unique navigation tasks (20 per dataset).
A subset of example tasks from the Hamburg dataset is provided in the appendix.
In the following, we refer to a task as a single Start-to-End street navigation problem, while a trial refers to a single model response to a specific task.
Each navigation task was evaluated once per model and context condition.
This results in a total of 240 trials (3 models \( \times \) 2 context conditions \( \times \) 40 navigation tasks).

% How were the trial responses stored?

After trial execution, each model's response was saved in a database. In the case of an exceedingly verbose model response, the response was truncated to contain only the relevant navigational instructions which we intend to investigate in this study.

% How was the obtained data evaluated and which statistical tools were used?

\section{Evaluation Metrics}

% Responses were reviewed manually against Google Maps.

All responses were then reviewed manually by comparing the generated instructions against Google Maps.
When looking at any response, the objective was to determine whether the produced steps could be executed in sequence to solve the navigation task.
If this was the case, the response was labelled as correct, otherwise it was labelled as incorrect.
Since the responses were labelled manually by a single evaluator, they may contain some subjective judgement in a few borderline cases.

% What does correct/incorrect mean in this study?

This means that just one incorrect instruction in any LLM response, control or test group, would consequently render the entire response incorrect.
A trial was labelled as incorrect if the response contained at least one instruction that (i) referenced a non-existing street, (ii) required an impossible turn, or (iii) produced a disconnected route.
Our validation does not take into account any further measures like distance measures or number of turns.
While these additional measures could provide interesting insights, they are outside the scope of this study.
The trial success rate is therefore defined as the proportion of navigation trials which were labelled as correct over the total number of navigation trials conducted.

\[
\text{Trial Success Rate} \;=\; \frac{N_{\text{correct}}}{N_{\text{total}}}
\]


% How was the trial success rate calculated?

After all responses were labelled, we were thus able to calculate trial success rates for the control and test groups.

% Conclusion of the Methods chapter.

This concludes our description of the methods used to conduct this study.
In the following chapter, we will present the results obtained from the experiments.