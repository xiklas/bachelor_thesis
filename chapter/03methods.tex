%!TEX root = ../thesis.tex
\chapter{Methods}
\label{ch:03methods}

% Chapter Introduction:
% Outlines the scope and structure of the Methods chapter.

Our research hypothesis states that the navigation capabilities of large language models may be significantly improved by the inclusion of qualitative geographic context.
To test our hypothesis, we designed an experimental setup involving large language models, qualitative geographic context and navigation tasks.
Our approach can be broken down into the data used, the configuration of the LLMs - including the context enrichment setup -, and ultimately the procedures used to conduct the experiments.
To evaluate the results, we define a strict correctness criterion and compute task success rates for the control and test groups.


% Data Acquisition and Preparation:
% Describes how the data used in the experiments was collected and prepared.

\section{Data Acquisition and Preparation}

% Why the data is not readily available on the internet.

The first step in our experimental setup is the generation of dipole relations describing topological relationships in street networks which can then be used as qualitative geographic context for our LLMs.
While high quality geographic datasets on street networks are available at no additional cost from various sources such as OpenStreetMap, these datasets typically do not include qualitative geographic descriptions.
The most common way of encountering street network data is in the form of graphml files which describe the street network as a graph of nodes and edges:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{chapter/hamburg.png} % Reduced to 60% of text width
    \caption{Graph representation of area of interest in Hamburg, Germany as used in this study.}
    \label{fig:graphic6}
\end{figure}

% Which data was downloaded and how was it processed to generate the dipole relations.

As basis for our experiments, we downloaded two of these graphs from the OpenStreetMap database using OSMnx, a powerful Python library capable of handling and processing OpenStreetMap data.
In order to ensure a reasonable degree of geographic variation, we selected two different cities as sites for our datasets: Hamburg and Münster.
This way, we end up with one dataset per city, each containing a varying number of nodes and edges.
To extract qualitative descriptions from these datasets, we implemented an algorithm capable of generating dipole relations in natural language which describe the topology of any graph given to the algorithm.
In essence, the algorithm works by iterating over all nodes and creating dipole relations for each intersection.
While the full algorithm is provided in the appendix, a conceptual description of the algorithm in pseudocode is given here:

\begin{algorithm}
\caption{Generate Street Descriptions from OSM}
\label{alg:street_desc}
\begin{algorithmic}[1]
\Require Bounding box
\Ensure Text descriptions for streets in bounding box
\State Download road network for bounding box
\State Remove motorways and isolated nodes
\For{each street name in network}
    \State Collect all road segments with this name
    \State Keep largest connected component
    \State Find main end-to-end path
    \State Orient path consistently (S$\to$N or W$\to$E)
    \For{each junction along path}
        \State Inspect connected streets
        \State Use bearings to classify as left/right/crossing
        \State Generate natural-language statement
    \EndFor
\EndFor
\State Export all descriptions to file
\end{algorithmic}
\end{algorithm}

% How was the data stored and how can the data be described.

Following this method, we were able to generate a set of dipole relations for each of our initial street network datasets.
These relations were stored in the form of simple .txt files, with one relation per line.
A full example of these relations is given in the appendix. 
To demonstrate the relations here, a small excerpt may be helpful:

\begin{tcolorbox}[title={Excerpt of qualitative relations (Hamburg)}, colback=white]
\small
\begin{verbatim}
Borchlingweg begins at the intersection with Ansorgestraße, Halbmondsweg.
Stindeweg then branches off to the right.
Langmaackweg then branches off to the right.
\end{verbatim}
\end{tcolorbox}



After discussing the data acquisition process, we now focus on a detailed description of the configuration of the LLMs used in this study.

% Which LLMs were selected and how were they configured.

\section{LLM Configuration}

% Why using the proprietary web interfaces is impractical for this study.

While the most common way for users to interact with large language models is to use their proprietary web interfaces, we identified this approach to be impractical for our needs;
namely to test multiple configurations of LLMs in a systematic manner.
While most LLM providers also offer APIs to interact with their models, this approach would have introduced additional programming overhead for this project.

% Why openrouter was selected and how the platform works.

One additional solution to access a wide range of current or legacy LLMs through a unified interface is to use a platform like OpenRouter, which is the platform we have chosen to use for this study.
Through it's user-friendly web-interface it is possible to query multiple LLMs concurrently without any additional programming effort.
It is important to note however, that even though OpenRouter makes it possible to query multiple LLMs at the same time, this does not mean that the queried models share a common context window or share any other information between each other.

% Which models were selected and why.

New models arrive on the market frequently, making it difficult to test "the latest" or "state of the art" models.
After all, a model with significantly greater capabilities in various areas could be just around the corner at any given time.
Nevertheless, we have selected three models which we consider to be widely used and capable of handling navigation tasks due to their advertised abilities of performing multi-step reasoning tasks.
Our selection of models for this study therefore consists of OpenAI's GPT-4o, Google's Gemini 2.5 Pro as well as Anthropic's Claude Sonnet 4.5.

% How was the qualitative context provided to the models?

The dipole relations generated by the process described in the previous section were stored in a simple .txt file.
For the navigation tasks, this file was provided to the models using OpenRouter's file upload (attachment) feature, allowing the models to reference the contained relations while generating a route.
To ensure the model responses were free of any web-search result contamination, we switched off any web-search tools available and used a simple system prompt telling the models to use their own inherent knowledge to solve the given tasks only.
In the trials conducted with additional qualitative geographic context, the system prompt was extended to instruct the models to use the provided dipole relations when figuring out a route.
Other than that, no further changes were made to the model's default configurations, making the setup easy to replicate and true to real-world usage scenarios.

% How was the experimental procedure designed?

\section{Experimental Design and Procedure}

% Traditional A/B testing approach with Test and Control Group.

Our experimental design follows a traditional A/B-testing approach, where we compare the performance of a Control Group against the performance of a Test Group.
In our case, the Control Group consists of LLMs performing navigation tasks on their own, without any additional context.
Respectively, the Test Group consists of LLMs performing the same navigation tasks, but with access to our dipole relations.
While the Test Group performs the exact same tasks as the Control Group, it was ensured that no memories of previous trials were available to the models in the Test Group sessions by starting each individual trial of both groups in a fresh session, disconnected from any previously conducted trials.

% How were the navigation tasks designed and executed?

To generate problem statements without any bias towards certain areas or streets for each dataset, we extracted the set of available street names from the original graphml data.
These lists were then each sampled randomly 20 times, with the resulting street names serving as the start-points for the navigation tasks for the given dataset.
This process was then repeated and another random 20 items were selected from each list to serve as the end-points for the tasks.
In total, this sums up to 40 unique navigation tasks over both datasets. Since each task was executed for both control and test conditions using all three models, this results in a total of 240 evaluated trials over the course of our study.

% How were the trial responses stored?

After trial execution, each model's response was saved in a database. In case of an exceedingly verbose model response, the response was truncated to contain only the relevant navigational instructions which we intend to investigate in this study.

% How was the obtained data evaluated and which statistical tools were used?

\section{Evaluation Metrics}

% Responses were reviewed manually against Google Maps.

All responses were then reviewed manually by comparing the produced instructions against Google Maps, one of the most widely used geographic information systems on the internet.
When looking at any response, the objective was to determine whether the produced steps could be executed in sequence to solve the navigation task.
If this was the case, the response was labelled as correct, otherwise it was labelled as incorrect.
Since the responses were labelled manually by a single evaluator, they may contain some subjective judgement in a few borderline cases.

% What does correct/incorrect mean in this study?

This means that just one incorrect instruction in any LLM response, control or test group, would consequently render the entire response incorrect.
Examples of incorrect instructions include but are not limited to referencing non-existing streets or making impossible turns.
Our validation does not take into account any further measures like distance measures or number of turns.
While these additional measures could provide interesting insights, they are outside the scope of this study.
The task success rate is therefore defined as the proportion of navigation tasks which were labelled as correct over the total number of navigation tasks conducted.

\[
\text{TaskSuccessRate} \;=\; \frac{N_{\text{correct}}}{N_{\text{total}}}
\]


% How was the task success rate calculated?

After all responses were labelled, we were thus able to calculate task success rates for the control and test groups.

% Conclusion of the Methods chapter.

This concludes our description of the methods used to conduct this study.
In the following chapter, we will present the results obtained from the experiments.