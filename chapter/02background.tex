\chapter{Background}
\label{ch:02background}

% Chapter Introduction
% Scope & Structure

This chapter provides the technical and theoretical background on the topic of navigation using large language models as well as on related topics which are essential for this thesis.
We will first discuss the general capabilities of LLMs, before narrowing down on their performance in spatial reasoning. Afterwards, we will review research on qualitative representations of topological data as well as context enrichment techniques for LLMs and observe if these techniques have been applied to study LLM performance in navigation tasks.


% What is an LLM?
\section{Large Language Models}

The large language model, commonly abbreviated as "LLM", is the central technlology this study revolves around.
While the history of LLMs is a fascinating topic in its own and can be traced back to first attempts at language modeling in the 1950s \citep{minaee_large_2025}, it is to extensive to be covered in this thesis, and also not what our research is about.
Therefore, we are going to focus on a purely practical overview on LLMs and their relevant characteristics to this study.

Large language models are the latest development and a specific subclass of language models in general \citep{minaee_large_2025}.
In practice, the challenge large language models aim to adress is the prediction of the next token in a given sequence of tokens \citep{minaee_large_2025}.
For example, given the input tokens (tokens can be thought of as words or parts of words) "Roses are", a large language model would attempt to predict the next token, which in this case could be "red".
Adding the predicted token to the input sequence, the model could then attempt to predict the next token and so on.
This process is known as autoregressive generation and applicable in other domains such as computer vision as well \citep{xiong_autoregressive_2025}.
To continue with the previous example, the next tokens after "Roses are red" could be "violet", with the prediction process eventually resulting in the sentence "Roses are red, violets are blue".

Creating a model that is able to perform this kind of token prediction and deliver acceptable results is by no means a trivial endeavor.
In fact, one of the biggest challenges with earlier language models such as RNNs (recurrent neural networks) was that they were often unable to maintain cohesion over longer sequences of tokens, making them unsuitable for practical use cases \citep{johnston_revisiting_2025}.


Modern large language models mitigate this issue by making use of several key enabling factors, the first one we will discuss is the transformer architecture.
The transformer architecture allows every token in a sequence to attend every other token during token prediction, enabling coherence over much longer sequences.
This architecture itself is realised through self-attention layers in the model architecture \citep{vaswani_attention_2017}.
All experiments conducted in this thesis are therefore partially enabled by this breakthrough architecture, without which the generation of lengthy, coherent text sequences using the LLMs we employ today would probably not be possible. 

Another key factor driving large language models is the availability of sufficient training data.
To achieve high performance, LLMs need to be trained on vast amounts of text data.
This data is usually scraped from books or the public internet.
Although exact figures on training dataset sizes are difficult to obtain for current models, even early models were trained on datasets containing billions of tokens \citep{minaee_large_2025}.

In the pre-training process, the model is trained using the training data, often to minimize prediction error.
This means that the model, consisting of a substantial number of parameters (often billions) is adjusted iteratively.
In each iteration, the model makes predictions and the prediction error is calculated.
Using this error, the parameters of the model are adjusted and the process is repeated until some criteria are met.
In addition to pre-training, the model can also be fine tuned to allow for even better results \citep{minaee_large_2025}.

There are countless additional details that can be studied about large language models and their training process..
For the purpose of this thesis however, this brief explanation should suffice to understand the LLM as a recent technology capable of generating coherent text:
If it can generate text on a wide variety of topics after all, why wouldn't it be able to generate text representing navigational instructions as well?

GPT-3 released by OpenAI in 2020 is considered by many to be the first example of a large language model \citep{minaee_large_2025}.

% What are emerging capabilities of LLMs?

\section{Emerging Abilities of LLMs}

Beyond mere language understanding and generation, LLMs exhibit further exiting abilities enabled by their large scale, namely emerging abilities.
Emerging abilities describe a set of abilities LLMs have displayed, while not being explicitly trained for these abilities.
The defining characteristic of emerging abilities is that they are not simply a scaled up version of smaller models' abilities.
Rather, they only appear once a certain model size is reached.
Examples for these abilities include in-context learning or reasoning abilities.
In-context learning allows LLMs to learn new tasks based on a few new examples provided in the input, without any additional training.
Reasoning abilities describe the ability of LLMs to solve problems that require multiple sequential steps to arrive at a solution, for example in the domain of math \citep{wei_emergent_2022}.

These emerging abilities are of particular interest to our study.
Solving navigational tasks may require not only the mere generation of text describing the route, but also an understanding of the spatial context to begin with.
With their emerging abilities, LLMs may be able to perform these tasks despite not being explicity trained for them (as of now we were not able to find any LLMs trained for navigation tasks, but finding LLMs with advertised abilities such as reasoning is easy today).


% Context Enrichment for LLMs

\section{Context Enrichment for LLMs}

In this section, we will discuss the concept of context enrichment for large language models.
Unfortunately, in many cases LLMs have shown to produce incrorrect or misleading outputs, a phenomenon often referred to as "hallucination".
Although the content of a hallucinatiion may seem plausible at first glance, it is often factually incorrect \citep{huang_survey_2025}.
The navigation example given in the introductory chapter of this thesis can be considered as an example of such a hallucination:
Although it appeared like a sensible set of directions to get from start to finish, under closer inspection the directions could be shown to contain many errors.
The initial plausability and semantic correctness are the key differences between a hallucination and random, degenerate output \citep{huang_survey_2025}.
To mitigate the frequency of hallucinations, researchers have come up with techniques to provide additional information to the LLM after the training process is complete \citep{minaee_large_2025}.

In practice, this is usually done by enriching the LLMs' context.
LLMs possess a finite context window, within which they can attend to tokens.
Traditionally, this context window would contain the chat history of the session as well as optional system prompts.
With context enrichment techniques however, additional information can be included in the context window \citep{minaee_large_2025}.

Retrieval augmented generation (or RAG) is one such technique.
With RAG, an additional external knowledge base is connected to the LLM system.
This external knowledge base can contain arbitrary sets of information, for example company documents or other niche specific knowledge which may be underrepresented in the training data.
When a user prompts the LLM, the system first queries the external knowledge base.
This query is directly derived from the user prompt.
Relevant snippets of the external knowledge base are then appended to the LLMs' context window.
Finally, after the context window has been enriched with this addtional information from the knowledge base, the LLM can start generating its output \citep{lewis_retrieval-augmented_2021}.

The effects of RAG on LLM hallucinations have been studied in previous research.
In knowledge-intensive tasks such as question asnwering, RAG has been shown to substantially reduce hallucinationsÂ \citep{gao_retrieval-augmented_2024}.
This may serve as a first indication that the technique could be useful for our study:
If we consider navigation tasks to be knowledge-intensive as well, RAG could potentially help LLMs generate accurate navigation instructions.

RAG has been implemented in various ways.
One specific RAG implementation relevant to our topic is graph RAG.
In this approach, the external knowledge base is not simply a collection of text chunks, but rather a graph structure.
This graph structure typically represents relationships between entities by modeling them as nodes and edges.
Similar to traditional RAG, the user prompt is used to query the graph structure for relevant nodes and edges.
These relevant nodes and edges are then converted to text snippets and appended to the LLM's context window.
In some cases, the graph structure may first have to be constructed from text, while in other cases a graph may be present in the first place \citep{edge_local_2025}.

Examples of graph structures include knowledge graphs or social networks, as well as road networks.
For our work this opens the possibility for a graph RAG system designed for improved LLM navigation as a long term goal.
In this thesis however, we will not implement such a system, but provide the additional geographic context directly within the prompt, emulating the effect of a RAG system.

% While a graph rag pipeline is a long term goal for the academic efforts surrounding this study, in our case we will simply emulate the effect by providing additional context in the prompt.

% What is topological geographic data and why is it relevant to this study.

\section{Qualitative Geographic Data}

As we have seen, LLMs possess the ability to generate coherent sequences of text \citep{minaee_large_2025}and their emerging abilities open the door to solving more complex tasks as well \citep{wei_emergent_2022}.
Additionaly, by using context enrichment techniques such as RAG, unwanted effects like hallucinations can be mitigated \citep{gao_retrieval-augmented_2024}.
In this thesis, we want to explore the potential of these techniques in the domain of navigation by testing whether LLM navigation can be improved by providing additional geographic context.
The missing piece of the puzzle is thus a suitable representation of geographic data which can then be provided to the LLM.

Geographic data can be represented in many ways.
A key distinction can be made between qualitative and quantitative geographic data.
While quantitative geographic data contains precise measurements such as distances or coordinates, qualitative geographic data describes properties and relationships of geographic entities \citep{lwin_quantitative_2012}. 

\begin{table}[h]
    \centering
    \begin{tabular}{p{0.25\textwidth} p{0.3\textwidth} p{0.35\textwidth}}
        \hline
        \textbf{Aspect} & \textbf{Qualitative representation} & \textbf{Quantitative representation} \\
        \hline
        Description &
        ``Examplestreet'' starts at the intersection with ``Teststreet''. \newline
        ``Examplestreet'' ends at the intersection with ``Endstreet''. &
        Name: Examplestreet \newline
        Length: 300 m \newline
        Width: 6 m \newline
        Starting coordinates: (1,1) \newline
        End coordinates: (6,7) \\
        \hline
    \end{tabular}
    \caption{Example of qualitative and quantitative representations of a street.}
    \label{tab:qual_quant_road}
\end{table}

In the example given in Table 2.1, we demonstrate the difference between qualitative and quantitative geographic data in the context of our research topic.
While the quantitative representation focuses on precise numbers such as "Length: 300 m", the qualitative representation describes the same road purely based on qualitative descriptions.
This does not mean that the two descriptions have the same information content, or that one representation is better than the other, however; both descriptions follow a unique paradigm and are suited for different tasks.
We hope that the qualitative representation may be better suited for LLM digestion, since as the example shows, qualitative geographic data can be represented nicely using natural language, the native medium of LLMs \citep{minaee_large_2025}.

So far, we have only seen a small example of qualitative geographic data.
In the end, we want to represent entire street networks in a qualitative manner.
To achieve this, a framework capable of representing topological data qualitatively is necessary.
Next, we will present such a framework, called the dipole calculus.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{chapter/dipole_relations.png} % Adjust width as needed
    \caption{All qualitatively different dipole relations that are necessary to describe a street network.}
    \label{fig:pasted_graphic}
\end{figure}

The dipole calculus is a qualitative spatial reasoning framework.
In the framework, elongated, oriented objects (such as road segments) are represented as directed line segments with a start and end point, called dipoles.
Pairing two of these dipoles together results in a relation that can be classified into one of several relational categories.
The set of these relational categories is finite.
Examples include relations where one dipole continues another, crosses it, or branches off from it.
This is an abstraction of the real world, and coordinates or distances are not represented in this framework.
In the end, this results in a framework which allows for qualitative reasoning on line-based geographic structures such as road networks \citep{moratz_condensed_2011}.

Although extended versions of the dipole calculus exist, all necessary dipole relations for our study are shown in Figure 2.1.
In the Figure, each dipole is represented by a unidirectional arrow.
Each dipole has a unique label (A-N) for identification.
For example, we see that dipole G branches off left from dipole B.
We can also see, that dipole A continues straight onwards from dipole B, and dipole E continues straight onwards from dipole A.
In practice, this means that a street may be broken down into several dipoles using this approach.
The mapping between dipoles and streets is thus not necessarily a strict one to one relationship:
While a dipole is always mapped to a single street, a street may be mapped to several dipoles.

\section{Datasources and GIS Tools}

Another key pillar for our research will be the identification of a reliable datasource for street networks, which can be transformed into dipole relations.
One such datasource is OpenStreetMap (OSM).
OpenStreetMap was created in 2004 and is a community driven, collaborative project providing free geographic data \citep{haklay_openstreetmap_2008}.
Because it is not a commercial product, OpenStreetMap relies on Volunteered Geographic Information (VGI) provided by citizens.
This has lead to the term "Citizen Sensor" being introduced to describe the means of data collection \citep{university_of_nottingham_gb_mapping_2017}.
Although this approach has benefits like removing corporate interests from the data, it also has downsides.
Since the data is provided by volunteers, the data quality may vary depending on the region of interest.
Some studies have investigated the data quality of OSM.
A metastudy conducted in 2013 synthesized several of these studies on OSM data quality. 
To summarize, the study found that OSM data was rapidly growing.
While the overall data quality was found to be heterogenous, meaning that it varied from region to region, the data quality was assessed to have improved over time \citep{sehra_assessment_2013}.
In an article published in 2014, researchers specifically compared the OSM road data available for Germany to proprietary datasets and found a 9\% difference in total network length, indicating that the OSM dataset contained relatively few gaps in the investigated region \citep{neis_recent_2014}.
The same article also notes that many studies mention an urban bias in OSM data, meaning that more densely populated areas tend to have better data coverage than rural areas \citep{neis_recent_2014}.
While this may be a limitation for other use cases, for our study this may not be a major issue, since we are investigating navigation tasks in urban scenarios, where the coverage reportedly tends to be better.
Even though we cannot ignore the fact that OSM data quality may vary, some researchers have shown that it is a robust choice for practical implementations.
In a conference paper from 2011, researchers investigated the use of OSM data for real time routing.
The researchers successfully demonstrated that OSM data was a suitable choice for both server side and hand held routing implementations \citep{luxen_real-time_2011}.
For us, this indicates that OSM data may be a suitable choice for our research regarding improved LLM navigation, especially since we are mainly focused on urban environments.

Many studies analyzing or utilizing OSM data have suffered from poor reproducibility and small sample sizes.
To adress these issues, a research initiative called OSMnx was created in 2017.
OSMnx provides an open source Python library, which allows users to easily download and visualize street networks from OpenStreetMap \citep{boeing_osmnx_2017}.
In this study, we will make use of OSMnx to obtain the street networks we require for our experiments.

Further, we will require a reliable tool to validate the generated navigation instructions.
Since the validation in this study will be done manually, we need a tool with a user friendly interface and reliable data coverage.
Also, because we do not want to validate the instructions on the same data source we obtained the street networks from, we will not use OpenStreetMap for this purpose.
Instead we will use a tried and tested commercial product called Google Maps.

Google Maps is a web based mapping platform which originated from the Australian company Where 2 Technologies, which was acquired by Google in 2004 \citep{noauthor_google_2025}.
In a recent report from 2020, Google, the company behind Google Maps, claims that the platform counts over 1 billion monthly active users \citep{noauthor_look_2020}.
Additionally, a survey conducted on 511 smartphone users in 2018 found that 67\% of respondents used Google Maps as their primary navigation app \citep{noauthor_popularity_nodate}.
In 2019 Google claimed that the data they use for Google Maps was sourced from over 1000 third party services globally \citep{noauthor_google_2019}.

% Introduction to topological geographic data.

Our study heavily relies on the concept of topological geographic data, which has been widely used and investigated already.
In this section we will introduce the concept and explain its relevance to our research.
To understand topological data, we may look at the following example of a subway map:

% Subway Map Figure.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/subway_map.png} % Adjust width as needed
    \caption{Arbitrary section of a london tube map.}
    \label{fig:pasted_graphic}
\end{figure}

% Explanation of Subway Map Figure and its relevance to topological data.

In Figure 1.3, we present an arbitrary cutout of the London tube map, containing sections of various lines such as the central line (red), the circle line (yellow) or the district line (green).
Besides the set of lines, the map also contains a set of stations such as "Westminster" or "Embankment" as well as the famous "Oxford Circus" station.
The map can thus be thought of as a set of nodes (stations) and edges connecting the nodes (lines).
Apart from this, the map does not contain any further information such as concrete distances between stations or their exact geographic locations in terms of latitude and longitude.

% What is the benefit of topological geographic data?

The key takeaway here is that the map serves the simple purpose of allowing users of the tube network to navigate from one station to another, by highlighting their connections and abstracting away anything else.
This abstraction allows for a very clean and efficient representation of otherwise complex networks.
It has been shown that such topological representations significantly aid human navigation in various scenarios.
Because of this, in many cases around the world such as public transport networks, topological representations like the tube map are used in practice.

% What does this have to do with our research?

Topological representations of geographic data are not limited to public transport networks however.
In fact, many other use cases for topological data exist.
For our research, we are particularly interested in road networks, which can also be represented in a topological manner.
To achieve a topological representation of a road network, we simply switch out stations for intersections and lines for roads connecting these intersections.
Again, we abstract away any further information such as distances or exact geographic coordinates.
What we are left with is a simplified representation of the initial network.
We suggest that using this simplified representation may aid LLMs in solving navigation tasks.

% Section on Dipole Relations of topological data.

\section{Dipole Representations of Topological Data}

% Intro on Dipole Relations.

As we have seen in the previous section, we can represent geographic data in the form of topological networks, describing connections between nodes.
In this section, we will present the technique of qualitatively describing such topological data using dipole relations.

% Figure on the dipole relations needed for our study.

% Explanation of Dipole Relations Figure.

By using dipole relations, an entire graph structure can thus be represented in an elegant way using natural language by simply aggregating qualitative statements like "Street A starts at Intersection of B,C and G" or "Street F branches off to the left from Street A".
Dipole relations have been successfully implemented in the field of robotics, where they were used to allow robotic agents to navigate through unknown environments.

% Section on Current Navigation Systems.

\section{Current Navigation Systems}

% Intro on Current Navigation Systems.

Navigation systems have been around for a long time.
For the average consumer, GPS based systems like Google Maps or Apple Maps to name a few, have become the norm when traveling by foot, bike or car.

% Section on Navigation as a Spatial Reasoning Task.

\section{Navigation: A Spatial Reasoning Task}

Since we are dealing with navigation tasks in this thesis, it is interesting to take a look at the abilities usually deemed necessary to successfully engage in the activity of navigation.

% Section on the reasoning capabilities of LLMs.

\section{Reasoning Capabilities of Large Language Models}

% Intro on LLMs.

The entire history of large language models is too vast and extensive to be covered in its entirety in this thesis.
However, this should not prevent us from giving a brief overview of the technology here.
We also aim to explain which of their characteristics leads us to believe that they could be capable of handling the navigation tasks we will confront them with later on.

% Where do LLMs come from?

The origins of LLMs lie in the field of natural language processing (NLP), where they were initially developed to perform tasks such as text generation and translation.
Although the specific architectures of these models have evolved since their inception, the underlying principles have remained rather consistent: LLM's are trained on vast amounts of text data (usually scraped from the internet) to learn patterns and relationships within the training data. Subsequently, if training was successful, the attained models, consisting of millions or even billions of parameters, are then able to generate seemingly coherent text by predicting the next words (or more accurately, tokens) in a sequence.

% What are the most well knwon LLMs?

Some of the most well known LLMs today include OpenAI's GPT series (which first brought the technology to the market) or Google's Gemini models. It is no secret however, that since the 2020s, a large number of competitors have entered the market with their own proprietary models.

% What was the initial use case for LLMs?

As mentioned, the primary potential for LLMs was initially identified in the field of natural language processing.
With the steady increase in training data and model size however, new capabilities began to emerge.
As early as 2021, researchers observed that LLMs were able to pass standardized tests such as the SAT (a test used for college admissions in the United States of America) or GRE (a similar test used for admissions to graduate schools), despite not being explicitly trained for these tasks.
Although previous artifical intelligence systems had already been able to perform well on specific tasks, such as playing chess or even eventually beating human players at the game of Go,, LLMs were thus the first models to demonstrate a more generalized ability to solve problems across a wide range of domains.

% What happened next (reasoning capabilities)?

Since then, the development of LLMs more capable than the original models has continued and no end is in sight. The increase in these models' abilities can be attributed to several factors such as larger training datasets, higher context windows and even more advanced architectures.
It didn't take much longer until big tech companies began to advertise their models with claims that their models were capable of reasoning, and thus being more capable of solving problems in domains such as math, programming and logic.
The term LRM (large reasoning model) was even introduced to describe models with such capabilities.
While certainly a valuable selling point, the actual reasoning capabilities of LLMs have been a topic of debate among scholars ever since.
This study will not attempt to settle this debate in one way or another, but is instead concerned with the practical abilities LLMs showcase when confronted with rather complex problems.

% How have their reasoning capabilites been studied?

To study their abilities when faced with reasoning tasks, researchers have come up with various benchmarks.
One of the most well known benachmarks is the FrontierMATH benchmarks

...

% What is the summary of LLM reasoning capabilities?

To summarize, while their abilities in reasoning tasks are by no means perfect, recent LLMs have proven to be more capable than ever before, and the trend is likely to continue in the foreseeable future.
This opens the door to confront LLMs with spatial reasoning tasks such as navigation, which will be the topic of the upcoming section.

% Section on LLM Spatial Reasoning Capabilities.

\section{LLMs in Spatial Reasoning and Navigation}

% Intro on LLMs in Spatial Reasoning and Navigation.

As we have seen, LLMs abilities to perform complex tasks requiring the use of a process similar to multi step reasoning has increased without any signs of slowdown over the past five years.
Although we cannot infer from this fact alone that LLMs are capable of solving issues in spatial reasoning as well, these new abilities may hint at their use in the field of geographic information science (GIScience).
While the discipline has identified several promising applications for LLMs in the domain, not all the research has concerned itself with their abilities regarding navigation tasks.

% What has been done so far?

Among several other applications, one paper published in 2025 by X et al. highlights the potential of LLMs to serve as natural language interfaces for GI systems (Geo-Information Systems):
In summary, LLMs could be used to allow users to interact with spatial data in new ways by using human language, thereby democratizing access to sophisticated GIS analysis.

If we want to apply this concept to navigation tasks however, we need to accept that LLMs have been shown to perform rather poorly in this area:
In a study conducted by Y et al. in 2025, several LLMs were tested on navigation tasks and their performance could be shown to be lacking.
While the exact reasons for LLMs shortcomings in this area are not part of this thesis, we theorize that a lack of qualitative geographic descripitions in the training data used to train these LLMs may be a significant factor.

% What is the summary on LLM Spatial Reasoning abilities?

While it was proposed that LLMs could serve as natural language interfaces, and their navigational capabilities were shown to be lacking, little work has been done to find ways to alleviate their shortcomings in this regard.
Other work focuses on the use of LLMs to create fully autonomous navigation agents using computer vision and robotics, which - although certainly impressive - is outside the scope of this thesis.
Despite the increase in reasoning capabilities of LLMs in other domains, which were presented in Chapter 1.2.1, using LLMs for navigation tasks seems to be a dead end as of today.
In the next section, we will present a proven technique to enhance LLM performance in various domains.

% Section on Context Enrichment Techniques for LLMs.

\section{Context Enrichment Techniques for LLMs}

% Intro on Context Enrichment Techniques for LLMs.

After several studies presented convincing evidence concerning hallucinations and other shortcomings of LLMs, researchers began to look for possible techniques to reduce the occurence of such issues. 
With context enrichment techniques, one promising approach was quickly identified:
To account for blind spots in the datasets used to train the LLMs, researchers began to allow LLMs to access additional knowledge when presented with a user query.
