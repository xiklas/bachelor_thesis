\chapter{Technical Background}
\label{ch:02background}

% Chapter Introduction
% Scope & Structure

This chapter provides the technical and theoretical background on the topic of navigation using large language models as well as on related topics which are essential for this thesis.
We will first discuss the general capabilities of LLMs, before narrowing down on their performance in spatial reasoning. Afterwards, we will review research on qualitative representations of topological data as well as context enrichment techniques for LLMs and observe if these techniques have been applied to study LLM performance in navigation tasks.

% What is topological geographic data and why is it relevant to this study.

\section{Topological Geographic Data}

% Introduction to topological geographic data.

Our study heavily relies on the concept of topological geographic data, which has been widely used and investigated already.
In this section we will introduce the concept and explain its relevance to our research.
To understand topological data, we may look at the following example of a subway map:

% Subway Map Figure.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/subway_map.png} % Adjust width as needed
    \caption{Arbitrary section of a london tube map.}
    \label{fig:pasted_graphic}
\end{figure}

% Explanation of Subway Map Figure and its relevance to topological data.

In Figure 1.3, we present an arbitrary cutout of the London tube map, containing sections of various lines such as the central line (red), the circle line (yellow) or the district line (green).
Besides the set of lines, the map also contains a set of stations such as "Westminster" or "Embankment" as well as the famous "Oxford Circus" station.
The map can thus be thought of as a set of nodes (stations) and edges connecting the nodes (lines).
Apart from this, the map does not contain any further information such as concrete distances between stations or their exact geographic locations in terms of latitude and longitude.

% What is the benefit of topological geographic data?

The key takeaway here is that the map serves the simple purpose of allowing users of the tube network to navigate from one station to another, by highlighting their connections and abstracting away anything else.
This abstraction allows for a very clean and efficient representation of otherwise complex networks.
It has been shown that such topological representations significantly aid human navigation in various scenarios.
Because of this, in many cases around the world such as public transport networks, topological representations like the tube map are used in practice.

% What does this have to do with our research?

Topological representations of geographic data are not limited to public transport networks however.
In fact, many other use cases for topological data exist.
For our research, we are particularly interested in road networks, which can also be represented in a topological manner.
To achieve a topological representation of a road network, we simply switch out stations for intersections and lines for roads connecting these intersections.
Again, we abstract away any further information such as distances or exact geographic coordinates.
What we are left with is a simplified representation of the initial network.
We suggest that using this simplified representation may aid LLMs in solving navigation tasks.

% Section on Dipole Relations of topological data.

\section{Dipole Representations of Topological Data}

% Intro on Dipole Relations.

As we have seen in the previous section, we can represent geographic data in the form of topological networks, describing connections between nodes.
In this section, we will present the technique of qualitatively describing such topological data using dipole relations.

% Figure on the dipole relations needed for our study.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/dipole_relations.png} % Adjust width as needed
    \caption{All qualitatively different dipole relations necessary to describe a street network.}
    \label{fig:pasted_graphic}
\end{figure}

% Explanation of Dipole Relations Figure.

By using dipole relations, an entire graph structure can thus be represented in an elegant way using natural language by simply aggregating qualitative statements like "Street A starts at Intersection of B,C and G" or "Street F branches off to the left from Street A".
Dipole relations have been successfully implemented in the field of robotics, where they were used to allow robotic agents to navigate through unknown environments.

% Section on Current Navigation Systems.

\section{Current Navigation Systems}

% Intro on Current Navigation Systems.

Navigation systems have been around for a long time.
For the average consumer, GPS based systems like Google Maps or Apple Maps to name a few, have become the norm when traveling by foot, bike or car.

% Section on Navigation as a Spatial Reasoning Task.

\section{Navigation: A Spatial Reasoning Task}

Since we are dealing with navigation tasks in this thesis, it is interesting to take a look at the abilities usually deemed necessary to successfully engage in the activity of navigation.

% Section on the reasoning capabilities of LLMs.

\section{Reasoning Capabilities of Large Language Models}

% Intro on LLMs.

The entire history of large language models is too vast and extensive to be covered in its entirety in this thesis.
However, this should not prevent us from giving a brief overview of the technology here.
We also aim to explain which of their characteristics leads us to believe that they could be capable of handling the navigation tasks we will confront them with later on.

% Where do LLMs come from?

The origins of LLMs lie in the field of natural language processing (NLP), where they were initially developed to perform tasks such as text generation and translation.
Although the specific architectures of these models have evolved since their inception, the underlying principles have remained rather consistent: LLM's are trained on vast amounts of text data (usually scraped from the internet) to learn patterns and relationships within the training data. Subsequently, if training was successful, the attained models, consisting of millions or even billions of parameters, are then able to generate seemingly coherent text by predicting the next words (or more accurately, tokens) in a sequence.

% What are the most well knwon LLMs?

Some of the most well known LLMs today include OpenAI's GPT series (which first brought the technology to the market) or Google's Gemini models. It is no secret however, that since the 2020s, a large number of competitors have entered the market with their own proprietary models.

% What was the initial use case for LLMs?

As mentioned, the primary potential for LLMs was initially identified in the field of natural language processing.
With the steady increase in training data and model size however, new capabilities began to emerge.
As early as 2021, researchers observed that LLMs were able to pass standardized tests such as the SAT (a test used for college admissions in the United States of America) or GRE (a similar test used for admissions to graduate schools), despite not being explicitly trained for these tasks.
Although previous artifical intelligence systems had already been able to perform well on specific tasks, such as playing chess or even eventually beating human players at the game of Go,, LLMs were thus the first models to demonstrate a more generalized ability to solve problems across a wide range of domains.

% What happened next (reasoning capabilities)?

Since then, the development of LLMs more capable than the original models has continued and no end is in sight. The increase in these models' abilities can be attributed to several factors such as larger training datasets, higher context windows and even more advanced architectures.
It didn't take much longer until big tech companies began to advertise their models with claims that their models were capable of reasoning, and thus being more capable of solving problems in domains such as math, programming and logic.
The term LRM (large reasoning model) was even introduced to describe models with such capabilities.
While certainly a valuable selling point, the actual reasoning capabilities of LLMs have been a topic of debate among scholars ever since.
This study will not attempt to settle this debate in one way or another, but is instead concerned with the practical abilities LLMs showcase when confronted with rather complex problems.

% How have their reasoning capabilites been studied?

To study their abilities when faced with reasoning tasks, researchers have come up with various benchmarks.
One of the most well known benachmarks is the FrontierMATH benchmarks

...

% What is the summary of LLM reasoning capabilities?

To summarize, while their abilities in reasoning tasks are by no means perfect, recent LLMs have proven to be more capable than ever before, and the trend is likely to continue in the foreseeable future.
This opens the door to confront LLMs with spatial reasoning tasks such as navigation, which will be the topic of the upcoming section.

% Section on LLM Spatial Reasoning Capabilities.

\section{LLMs in Spatial Reasoning and Navigation}

% Intro on LLMs in Spatial Reasoning and Navigation.

As we have seen, LLMs abilities to perform complex tasks requiring the use of a process similar to multi step reasoning has increased without any signs of slowdown over the past five years.
Although we cannot infer from this fact alone that LLMs are capable of solving issues in spatial reasoning as well, these new abilities may hint at their use in the field of geographic information science (GIScience).
While the discipline has identified several promising applications for LLMs in the domain, not all the research has concerned itself with their abilities regarding navigation tasks.

% What has been done so far?

Among several other applications, one paper published in 2025 by X et al. highlights the potential of LLMs to serve as natural language interfaces for GI systems (Geo-Information Systems):
In summary, LLMs could be used to allow users to interact with spatial data in new ways by using human language, thereby democratizing access to sophisticated GIS analysis.

If we want to apply this concept to navigation tasks however, we need to accept that LLMs have been shown to perform rather poorly in this area:
In a study conducted by Y et al. in 2025, several LLMs were tested on navigation tasks and their performance could be shown to be lacking.
While the exact reasons for LLMs shortcomings in this area are not part of this thesis, we theorize that a lack of qualitative geographic descripitions in the training data used to train these LLMs may be a significant factor.

% What is the summary on LLM Spatial Reasoning abilities?

While it was proposed that LLMs could serve as natural language interfaces, and their navigational capabilities were shown to be lacking, little work has been done to find ways to alleviate their shortcomings in this regard.
Other work focuses on the use of LLMs to create fully autonomous navigation agents using computer vision and robotics, which - although certainly impressive - is outside the scope of this thesis.
Despite the increase in reasoning capabilities of LLMs in other domains, which were presented in Chapter 1.2.1, using LLMs for navigation tasks seems to be a dead end as of today.
In the next section, we will present a proven technique to enhance LLM performance in various domains.

% Section on Context Enrichment Techniques for LLMs.

\section{Context Enrichment Techniques for LLMs}

% Intro on Context Enrichment Techniques for LLMs.

After several studies presented convincing evidence concerning hallucinations and other shortcomings of LLMs, researchers began to look for possible techniques to reduce the occurence of such issues. 
With context enrichment techniques, one promising approach was quickly identified:
To account for blind spots in the datasets used to train the LLMs, researchers began to allow LLMs to access additional knowledge when presented with a user query.
