%!TEX root = ../thesis.tex
\chapter{Introduction}
\label{ch:01intro}

% Chapter Introduction

In this chapter, we introduce the research topic of navigation using large language models.
After briefly discussing the current capabilities of LLMs in navigation tasks, we review the existing body of research in this emergent area.
We then identify the research gap we aim to address in this thesis and formulate a corresponding research hypothesis.

% The Current State of Navigation using LLMs

\section{The Current State of Navigation using LLMs}

% Introduction to Research Topic

Today, users rely on large language models every day, with leading systems like ChatGPT processing over 2 billion user queries per day as of July 2025 \citep{openai_unlocking_2025}.
A recent journal article has highlighted the many unique use cases for LLMs, ranging from information retrieval to various other tasks such as drafting text or generating computer code \citep{chatterji_how_2025}.
With this many requests to ChatGPT alone and many other competing LLMs such as Google's Gemini or Anthropic's Claude also available on the market, it is possible to imagine that some users may have attempted to use LLMs for navigational tasks as well.
If that is indeed the case, we should study whether LLMs are actually capable of delivering accurate responses to such requests.
If it can be argued that they are not yet up to the task, we should also invest time into improving their performance in this regard.

In the following example depicted in Figure 1.1 we prompted GPT-4o with a simple navigation task to observe whether the model could successfully provide a useful answer to a simple path finding problem.
The prompt used to generate the response shown in Figure 1.1 was as follows:

\begin{quote}
    \textit{I just arrived at Münster central station and need to get to the Hafenweg. Please provide me with step-by-step walking directions to get there.}
\end{quote}

% Example Figure of User Navigation Task Reply using ChatGPT 4o

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/PastedGraphic-2.png} % Adjust width as needed
    \caption{GPT-4o response to a simple route planning task.}
    \label{fig:graphic1}
\end{figure}

% Why would users want to use LLMs for navigation?

Although alternative route planning solutions such as Google Maps or OpenStreetMap exist, the model response depicted in Figure 1.1 illustrates the potential of using LLMs as purely text-based interfaces for navigational tasks, as compared to the traditional map-based implementations.
For this concept to be viable in practice however, LLMs would have to be able to provide accurate and reliable responses, as mistakes in navigation can lead to significant problems in many scenarios.

% Map with Correct Route vs. GPT-4o Response

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter/PastedGraphic-3.png} % Adjust width as needed
    \caption{One possible correct route (green) for the example navigation task compared to various segments found in the GPT-4o response (red).}
    \label{fig:graphic2}
\end{figure}

% What is wrong with the LLM response?

Even though the model response shown in Figure 1.1 appears structurally sound and plausible at first glance, upon closer inspection there are several critical mistakes present in the response.
To understand the mistakes, we are going to break down the response step by step, starting with the first instruction:

\begin{quote}
    \textit{1. Exit Münster Hauptbahnhof through the main entrance onto Willy-Brandt-Allee.}
\end{quote}

Although exiting Münster Hauptbahnhof to reach the destination is certainly a sensible step, the actual best way would be to use the secondary exit away from the city center and towards the actual destination.
Also, a street called "Willy-Brandt-Allee" does not exist in Münster at the time of writing, rendering the instruction impossible to follow.
The second instruction is as follows:

\begin{quote}
    \textit{2. Turn right and walk southeast on Willy-Brandt-Allee toward the city center.}
\end{quote}

Although the destination indeed lies southeast of the central train station in Münster, this instruction is impossible, since the street mentioned does not exist in the first place.
Additionally, the direction "toward the city center" is incorrect, since the destination lies further away relative to the city center.
The next instruction reads:

\begin{quote}
    \textit{3. After about 500 meters, you'll reach Albersloher Weg. Turn left onto Albersloher Weg.}
\end{quote}
 
The "Albersloher Weg" is actually an existing street in Münster, and also somewhat close to the destination "Hafenweg".
However, turning onto this street based on the previous instruction is impossible, and taking this street based on the starting point of the route does not make sense navigationally.
Continuing with the next instruction:

\begin{quote}
    \textit{4. Continue along Albersloher Weg for about 1 km, passing the Aasee park area on your right.}
\end{quote}

This instruction is puzzling in many ways. 
For once, the destination does not lie one kilometer away from the Central Station, therefore traversal of any road for "about 1km" should lead to scepticism about the correctness of the instruction.
Further, the "Aasee Park area" exists in Münster, but it does not make sense to mention it in this example, since it is too far away from any point along the actual route, and it also is not located near the "Albersloher Weg".
With the next instruction, the mistakes made by ChatGPT-4o continue:

\begin{quote}
    \textit{5. When you reach the intersection with Hammer Straße, turn right.}
\end{quote}

Again, "Hammer Straße" is an actual street in Münster, however:
It does not intersect with the "Albersloher Weg" - and taking this street does not make sense in the context of the presented problem.
Finally, the last two instructions read:

\begin{quote}
    \textit{6. Walk along Hammer Straße for around 700 meters. You'll pass a few residential and commercial buildings.\\}
    \textit{7. Look for Hafenweg on your left. Turn left onto Hafenweg.}
\end{quote}

Again, these instructions are not viable, as the Hammer Straße and Hafenweg are not connected.
Whether there are "residential and commercial buildings" along the Hammer Straße is irrelevant, although it may as well be true.
In total, GPT-4o suggested several wrong and disconnected directions, a striking contrast compared to the actual route.
Additionally, traversal of a street was suggested that doesn't exist in the investigated city at the time of writing (Willy-Brandt-Allee).

Dr. Reinhard Moratz, the supervisor of this thesis, has experimented with the navigational capabilities of LLMs earlier this year and was able to make similar observations like this on their apparent struggle to provide useful answers.
This tendency seems to persist even in more recent models such as GPT-4o, as can be seen in the example above.



% What have observations like these led us to think about?

Experiments like these have left room for research systematically studying the shortcomings of contemporary LLMs in spatial reasoning, and if the inclusion of qualitative geographic context in the form of natural language dipole relations can significantly improve their performance in this regard. 
We thus conduct a series of experiments to evaluate the navigation capabilities of select LLMs across multiple geographic areas, both with and without the inclusion of qualitative geographic context.
In order to gain a clear picture of the current state of research in this area, we must first review the relevant literature.

% Research Overview & Research Gap

\section{Research Overview}

At the moment, no literature explores the impact of qualitative geographic context on navigation performance in LLMs.
Without any research, a clear verdict on the viability of LLMs as natural language interfaces for navigation tasks will remain inconclusive. 
While previous research has addressed the general capabilities of LLMs in reasoning tasks, it can not automatically be assumed that these capabilities translate to strong navigation performance in real world scenarios.
Many potential uses for LLMs in GIScience applications have been theorized, among those the possibility to act as natural language interfaces for spatial queries such as navigation.
The existing research regarding LLM navigation performance however paints a clear picture: Currently, LLMs are not able to perform navigation tasks reliably, and thus this potential use case remains unfulfilled.

This research alone is however not sufficient to fully dismiss the idea of using LLMs for navigation.
Few attempts have been made to improve their performance in this regard.
If research could identify techniques that significantly improve LLM navigation performance, the idea of their usage in this area could become practical in the future.
Even though one study alone will not be sufficient to fully explore this area and answer all open questions, it could provide first evidence on the viability of such techniques and serve as a benchmark for future research.

One technique that has shown promise in reducing shortcomings such as hallucinations in other areas where LLMs are applied is context enrichment.
By providing additional context to the model, blindspots in LLM training data such as recent events, niche topics or internal company data can be addressed by this method.
It seems likely, although unproven, that a similar blindspot could be manifest in the area of topological data required for urban navigation tasks.

Any attempts to addressed the issue of poor LLM navigation performance using context enrichment must however answer the initial question of how to best provide geographic context in a way that is suitable for LLMs.
Since LLMs mostly consume text data during training, we hypothesize that the geographic context should be present in the form of text as well.
Fortunately, spatial data is available in vast quantities on the internet for free.
Unfortunately, this data is usually not in a text based natural-language format.

A solution to addressed this tangential issue could be to utilize a framework for qualitatively describing topological data such as the dipole calculus.
The dipole calculus is a established framework that has been used in applications such as robotics.
In the framework, purely qualitative relations are defined to describe topological relations in an elegant manner.
These relations could be translated into natural language statements, suitable for LLM context enrichment.

In this study we therefore aim to show first empirical evidence on whether this technique of improving LLM navigation using qualitative geographic context could prove viable.
As mentioned, this research will addressed a gap in the existing literature, but will not be sufficient to fully explore the area.
The testing framework we establish can also be utilized by future researchers studying additional ways of improving LLM navigation performance.
In the end, this study will serve as a first step on the long-term path towards LLM usage in navigation tasks.

% Research Hypothesis

\section{Research Hypothesis}

Drawing from the current state of research, we propose that context enrichment using qualitative geographic relations may have a positive effect on LLM navigation performance.
Context enrichment has been shown to make LLM responses less prone to hallucinations in other domains, while dipole relations provide a proven framework for qualitatively describing topological data.
Combined, these techniques should aid the LLM and allow it to provide more accurate answer to navigational tasks.
We thus formulate the following research hypothesis H1: 
\begin{quote} 
    \textit{The inclusion of qualitative geographic context in the form of natural language dipole relations significantly improves the navigation performance of large language models.}
\end{quote}
The alternative hypothesis can thus be formulated as follows H0:
\begin{quote} 
    \textit{The inclusion of qualitative geographic context in the form of natural language dipole relations does not significantly improve the navigation performance of large language models.}
\end{quote}
In the following chapters, we will describe the methods used to test our hypothesis and present the results of our experiments.
The thesis will then conclude with a discussion of the findings and their meaning for future research in this area.